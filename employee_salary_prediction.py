# -*- coding: utf-8 -*-
"""employee salary prediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iGYXYAhkz8hUETbWQbhYwxxVVGbUncSW
"""

import pandas as pd

data=pd.read_csv(r"/adult 3.csv")

data.head(10)

data.tail(3)

data.shape

#null values
data.isna().sum() #mean mdeian mode arbitrary

print(data.workclass.value_counts())

data.workclass.replace({'?':'Others'},inplace=True)
print(data['workclass'].value_counts())

print(data['occupation'].value_counts())

data.occupation.replace({'?':'Others'},inplace=True)
print(data['occupation'].value_counts())

data=data[data['workclass']!='Without-pay']
data=data[data['workclass']!='Never-worked']
print(data['workclass'].value_counts())

print(data.relationship.value_counts())

print(data.gender.value_counts())

data.shape

#outlier detection
import matplotlib.pyplot as plt   #visualization
plt.boxplot(data['age'])
plt.show()

data=data[(data['age']<=75)&(data['age']>=17)]

plt.boxplot(data['age'])
plt.show()

data.shape

plt.boxplot(data['capital-gain'])
plt.show()

plt.boxplot(data['capital-gain'])
plt.show()

plt.boxplot(data['educational-num'])
plt.show()

data=data[(data['educational-num']<=16)&(data['educational-num']>=5)]

plt.boxplot(data['educational-num'])
plt.show()

plt.boxplot(data['hours-per-week'])
plt.show()

data.shape

data=data.drop(columns=['education']) #redundant features removal

data

from sklearn.preprocessing import LabelEncoder   #import libarary
encoder=LabelEncoder()                       #create object
data['workclass']=encoder.fit_transform(data['workclass']) #7 categories   0,1, 2, 3, 4, 5, 6,
data['marital-status']=encoder.fit_transform(data['marital-status'])   #3 categories 0, 1, 2
data['occupation']=encoder.fit_transform(data['occupation'])
data['relationship']=encoder.fit_transform(data['relationship'])      #5 categories  0, 1, 2, 3, 4
data['race']=encoder.fit_transform(data['race'])
data['gender']=encoder.fit_transform(data['gender'])    #2 catogories     0, 1
data['native-country']=encoder.fit_transform(data['native-country'])

data

x=data.drop(columns=['income'])
y=data['income']
x

from sklearn.pipeline import Pipeline
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score, classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.preprocessing import StandardScaler, OneHotEncoder

X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

models = {
    "LogisticRegression": LogisticRegression(),
    "RandomForest": RandomForestClassifier(),
    "KNN": KNeighborsClassifier(),
    "SVM": SVC(),
    "GradientBoosting": GradientBoostingClassifier()
}

results = {}

for name, model in models.items():
    pipe = Pipeline([
        ('scaler', StandardScaler()),
        ('model', model)
    ])

    pipe.fit(X_train, y_train)
    y_pred = pipe.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    results[name] = acc
    print(f"{name} Accuracy: {acc:.4f}")
    print(classification_report(y_test, y_pred))

import matplotlib.pyplot as plt
plt.bar(results.keys(), results.values(), color='skyblue')
plt.ylabel('Accuracy Score')
plt.title('Model Comparison')
plt.xticks(rotation=45)
plt.grid(True)
plt.show()

from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import joblib

# Train-test split
X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)

# Define models
models = {
    "LogisticRegression": LogisticRegression(max_iter=1000),
    "RandomForest": RandomForestClassifier(),
    "KNN": KNeighborsClassifier(),
    "SVM": SVC(),
    "GradientBoosting": GradientBoostingClassifier()
}

results = {}

# Train and evaluate
for name, model in models.items():
    model.fit(X_train, y_train)
    preds = model.predict(X_test)
    acc = accuracy_score(y_test, preds)
    results[name] = acc
    print(f"{name}: {acc:.4f}")

# Get best model
best_model_name = max(results, key=results.get)
best_model = models[best_model_name]
print(f"\nâœ… Best model: {best_model_name} with accuracy {results[best_model_name]:.4f}")

# Save the best model
joblib.dump(best_model, "best_model.pkl")
print("âœ… Saved best model as best_model.pkl")

import streamlit as st
import pandas as pd
import joblib

# Load the trained model
model = joblib.load("best_model.pkl")

# These should be the exact feature columns used during training after encoding
trained_columns = ['age', 'hours-per-week', 'experience',
                   'education_Bachelors', 'education_HS-grad', 'education_Masters',
                   'education_PhD', 'education_Some-college', 'education_Assoc',
                   'occupation_Adm-clerical', 'occupation_Armed-Forces', 'occupation_Craft-repair',
                   'occupation_Exec-managerial', 'occupation_Farming-fishing', 'occupation_Handlers-cleaners',
                   'occupation_Machine-op-inspct', 'occupation_Other-service', 'occupation_Priv-house-serv',
                   'occupation_Prof-specialty', 'occupation_Protective-serv', 'occupation_Sales',
                   'occupation_Tech-support', 'occupation_Transport-moving']

st.set_page_config(page_title="Employee Salary Classification", page_icon="ðŸ’¼", layout="centered")

st.title("ðŸ’¼ Employee Salary Classification App")
st.markdown("Predict whether an employee earns >50K or â‰¤50K based on input features.")

st.sidebar.header("Input Employee Details")
age = st.sidebar.slider("Age", 18, 65, 30)
education = st.sidebar.selectbox("Education Level", [
    "Bachelors", "Masters", "PhD", "HS-grad", "Assoc", "Some-college"
])
occupation = st.sidebar.selectbox("Job Role", [
    "Tech-support", "Craft-repair", "Other-service", "Sales",
    "Exec-managerial", "Prof-specialty", "Handlers-cleaners", "Machine-op-inspct",
    "Adm-clerical", "Farming-fishing", "Transport-moving", "Priv-house-serv",
    "Protective-serv", "Armed-Forces"
])
hours_per_week = st.sidebar.slider("Hours per week", 1, 80, 40)
experience = st.sidebar.slider("Years of Experience", 0, 40, 5)

# Step 1: Create initial DataFrame
input_dict = {
    'age': [age],
    'education': [education],
    'occupation': [occupation],
    'hours-per-week': [hours_per_week],
    'experience': [experience]
}
input_df = pd.DataFrame(input_dict)

# Step 2: One-hot encode like in training
input_encoded = pd.get_dummies(input_df)

# Step 3: Add any missing columns from training with 0
for col in trained_columns:
    if col not in input_encoded.columns:
        input_encoded[col] = 0

# Step 4: Reorder to match training feature order
input_encoded = input_encoded[trained_columns]

st.write("### ðŸ”Ž Processed Input for Model")
st.write(input_encoded)

if st.button("Predict Salary Class"):
    prediction = model.predict(input_encoded)
    st.success(f"âœ… Prediction: {prediction[0]}")

# Batch prediction section
st.markdown("---")
st.markdown("#### ðŸ“‚ Batch Prediction")
uploaded_file = st.file_uploader("Upload a CSV file for batch prediction", type="csv")

if uploaded_file is not None:
    batch_data = pd.read_csv(uploaded_file)
    batch_encoded = pd.get_dummies(batch_data)

    for col in trained_columns:
        if col not in batch_encoded.columns:
            batch_encoded[col] = 0
    batch_encoded = batch_encoded[trained_columns]

    batch_preds = model.predict(batch_encoded)
    batch_data['PredictedClass'] = batch_preds
    st.write("âœ… Predictions:")
    st.write(batch_data.head())
    csv = batch_data.to_csv(index=False).encode('utf-8')
    st.download_button("Download Predictions CSV", csv, file_name='predicted_classes.csv', mime='text/csv')

!streamlit run app.py

!pip install streamlit pyngrok

!ngrok authtoken 3032g18TzcG6a1eRUl8xOWg0HBf_GwU5YNPUh3a2jkeQG8Mh

import os
import threading

def run_streamlit():
    os.system('streamlit run app.py --server.port 8501')

thread = threading.Thread(target=run_streamlit)
thread.start()

from pyngrok import ngrok
import time

# Wait a few seconds to make sure Streamlit started
time.sleep(5)

# Create a tunnel to the Streamlit port 8501
public_url = ngrok.connect(8501)
print("Your Streamlit app is live here:", public_url)







